# Note:  The design of CycleGAN-balanced is a bit weird in the sense that the conventional notion of a domain A image and a domain B image does not apply.
# Therefore, it is not supported by the Ganslate framework unless tweaking some code as a hack (specifically, in the `get_metrics()` function file `ganslate/utils/metrics/val_test_metrics.py`)


project: "./projects/maastro_hx4_pet_translation/"

train:
    output_dir: "/workspace/Chinmay-Checkpoints-Ephemeral/HX4-PET-Translation/hx4_pet_cyclegan_balanced/"
    cuda: True
    n_iters: 30000      
    n_iters_decay: 30000  
    batch_size: 1
    mixed_precision: False
    seed: 1

    logging:
        freq: 50
        multi_modality_split:
            A: [1, 1]
            B: [1, 1]  # ldCT is the 2nd component
        wandb:
            project: "maastro_hx4_pet_translation"
            run: "cyclegan_balanced_lambdas10"
        
    checkpointing:
        freq: 1000

    dataset: 
        _target_: project.datasets.train_dataset.HX4PETTranslationTrainDataset
        root: "/workspace/Chinmay-Datasets-Ephemeral/HX4-PET-Translation-Processed/train"
        paired: False                    # Unpaired training
        require_ldct_for_training: True  # ldCT required for training
        patch_size: [32, 128, 128]   # (D,H,W)
        patch_sampling: uniform-random-within-body-sf
        focal_region_proportion: [0.6, 0.35, 0.35]  # (D,H,W)
        num_workers: 8

    gan: 
        _target_: project.modules.HX4CycleGANBalanced
        generator:  
            _target_: ganslate.nn.generators.Unet3D
            in_out_channels:
                AB: [2, 1]  # Both G's take 2 inputs and predict 1 output
                BA: [2, 1]  #
            num_downs: 4
            ngf: 64
            use_dropout: True

        discriminator:  
            _target_: ganslate.nn.discriminators.PatchGAN3D
            in_channels:
                B: 1  # Both D's evaluate a single modality (the PETs)
                A: 1  #
            n_layers: 3
            kernel_size: [4, 4, 4]
            ndf: 64

        optimizer:
            lr_D: 0.0001
            lr_G: 0.0002
            lambda_AB: 10.0
            lambda_BA: 10.0
            lambda_identity: 0
            proportion_ssim: 0

    metrics:
        discriminator_evolution: True
        ssim: False  # `False` because it's computed by with the dummy array included, and is hence wrong


val:
    freq: 1000
    dataset: 
        _target_: project.datasets.val_test_dataset.HX4PETTranslationValTestDataset
        root: "/workspace/Chinmay-Datasets-Ephemeral/HX4-PET-Translation-Processed/val"
        num_workers: 8
        supply_masks: False  # Do not supply masks -> less number of val metrics to compute, faster training 
        model_is_hx4_cyclegan_balanced: True  # Using HX4-CycleGAN-balanced
        use_patch_based_inference: True #
    sliding_window:                     # Enable sliding window inferer
        window_size: ${train.dataset.patch_size}
    metrics:   # Enabled metrics: MSE, MAE, PSNR, SSIM, NMI, Chi-squared histogram distance
        mse: True
        mae: True
        nmse: False
        psnr: True
        ssim: True
        nmi: True
        histogram_chi2: True
        cycle_metrics: False  # `False` because cycle in validation is hardcoded to be the default (naive) way
